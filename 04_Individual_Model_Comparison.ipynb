{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script for reaction time models with within-trial baseline dynamics. Simulations, analytical solutions, parameter recovery, fitting methods\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from matplotlib.pyplot import cm\n",
    "import warnings\n",
    "from scipy.stats import entropy\n",
    "from Scripts import behaviour\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(0)\n",
    "    \n",
    "class eLATER:\n",
    "    \"\"\"\n",
    "    Class for fitting eLATER model only (no baseline dynamics)\n",
    "    \"\"\"\n",
    "    def __init__(self, name, time,\n",
    "                 muR, sigR, muS, sigS, maxT):\n",
    "        self.name = name\n",
    "        self.time = time\n",
    "        self.muR = muR # sensory integration mean rate\n",
    "        self.sigR = sigR # sensory integration variance\n",
    "        self.muS = muS\n",
    "        self.sigS = sigS\n",
    "        self.maxT = maxT # maximum time for each probability distribution\n",
    "\n",
    "    def setDelayTimes(self, delays):\n",
    "        \"\"\" Adds delay times for given trial set to the class (this is kinda stupid, remove function and do it in one line somewhere else.... well I guess this depends on if the delays are simulated or \n",
    "        provided from data. Just leave it for now and figure that out as it comes)\n",
    "\n",
    "        Args:\n",
    "            delays (ndarray): distribution of delay times to sample from\n",
    "        \"\"\"\n",
    "        self.delayTimes = delays.astype(int)\n",
    "\n",
    "    def extended_later(self, muR, muS, sR, sigma):\n",
    "        \"\"\" Extended LATER model from Nakahara et al (2006) https://pubmed.ncbi.nlm.nih.gov/16971090/\n",
    "        \n",
    "        \n",
    "        Takes class input for fixed time parameters, plus additional arguments for the mean and variance of the baseline and sensory integration\n",
    "\n",
    "        Args:\n",
    "            muR (float): mean rate of rise for sensory integration\n",
    "            sR (float): variance of the rate of rise \n",
    "\n",
    "        Returns:\n",
    "            pT (ndarray): array of 1xt where each point is the probability of a reaction time equalling that time point (sums to 1)\n",
    "        \"\"\"\n",
    "        t = np.arange(1, self.maxT) #Need max time to normalize with other distributions\n",
    "        a = muR / muS\n",
    "        b = sR / muS\n",
    "        c = sigma / sR\n",
    "        \n",
    "        e1 = (1/t - a) ** 2\n",
    "        e2 = t ** 2 / (t ** 2 + c **2)\n",
    "        e3 = -1 / (2 * b **2)\n",
    "        pT = np.multiply(np.multiply(t + a * (c ** 2) / (t **2 + c ** 2) **(3/2), 1/((2 * math.pi)**(1/2)*b)), \n",
    "                        np.exp(e1 * e2 * e3))\n",
    "        pT = pT / np.sum(pT)\n",
    "        return pT\n",
    "    \n",
    "    def computeModel(self):\n",
    "        pTrialOnset, pTargetOnset = [np.zeros((self.time.size, self.delayTimes.size)) for _ in range(2)] \n",
    "        if hasattr(self, 'delayTimes') == True:\n",
    "            for i in range(self.delayTimes.size):\n",
    "                pTargetOnset[0:self.maxT-1,i] = self.extended_later(self.muR, self.muS, self.sigR, self.sigS) #change self.sigma to self.ouVar[self.delayTimes[i]] for changing cov\n",
    "                pTrialOnset[self.delayTimes[i]:self.delayTimes[i]+self.maxT,i] = pTargetOnset[0:self.maxT,i]\n",
    "        else:  \n",
    "            print(\"No delay distribution found. Please set via setDelayTimes first\")   \n",
    "        self.combined = pTrialOnset \n",
    "\n",
    "def fiteLATERModel(params, data):\n",
    "\n",
    "    # Set delay time bins to fit data to\n",
    "    minDelay = 750\n",
    "    maxDelay = 1250\n",
    "    delayBins = 10\n",
    "    delays = np.linspace(minDelay, maxDelay, delayBins)\n",
    "\n",
    "    # Set constants for model fitting\n",
    "    shift = 0.5\n",
    "    scale = 100\n",
    "    trialBins = 100\n",
    "\n",
    "    # Get Indices for delay bins\n",
    "    delayData = dict()\n",
    "    for i in range(delayBins):\n",
    "        if i == delayBins-1:\n",
    "            delayData[str(delays[i])] = data[(data['First Target Onset'] >= delays[i])] \n",
    "        else:\n",
    "            delayData[str(delays[i])] = data[(data['First Target Onset'] >= delays[i]) & (data['First Target Onset'] < delays[i+1])]\n",
    "\n",
    "    # Initialize model error\n",
    "    model_error = 0 \n",
    "\n",
    "    # Fit the model\n",
    "    try:\n",
    "        for delay in delays: # Loop model fit for same parameter set\n",
    "\n",
    "            # Set up the model\n",
    "            model = eLATER('Accumulator 1', time = np.arange(1,2000), muR = params[0], muS = params[1],\n",
    "                           sigR = params[2], sigS = params[3], maxT = 700)\n",
    "            model.setDelayTimes(np.linspace(delay, delay, 1)) # Set delay times equal to first delay bin\n",
    "            model.computeModel() # Run Model\n",
    "\n",
    "            # Align reaction times to delay bin\n",
    "            data = delayData[str(delay)]['Reaction Time: First Target'] + delay\n",
    "            data = data.to_numpy()\n",
    "            data_pdf, _ = np.histogram(data, bins = trialBins, range =(750, 2000), density = True)\n",
    "            \n",
    "            # Sample data from model \n",
    "            model_sample = np.random.choice(1999, 10000, p = normalize_rt_pdfs(model.combined))\n",
    "            model_pdf, _ = np.histogram(model_sample, bins = trialBins, range =(750, 2000), density = True)\n",
    "\n",
    "            # Rescale model and data\n",
    "            data_pdf = data_pdf + shift\n",
    "            model_pdf = model_pdf + shift\n",
    "            model_pdf = np.nan_to_num(model_pdf)\n",
    "            data_pdf = np.nan_to_num(data_pdf)\n",
    "\n",
    "            # Compute entropy between model and data, add to previous delay entropy\n",
    "            model_error += entropy(model_pdf, data_pdf) * scale \n",
    "            \n",
    "        return model_error #model error summed over all delay periods\n",
    "\n",
    "    except:\n",
    "        print('probabilities contain nan') #throw out bad models\n",
    "        return np.inf\n",
    "\n",
    "def normalize_rt_pdfs(pRT):\n",
    "    pT = np.sum(pRT, 1) / np.shape(pRT)[1] \n",
    "    return pT / np.sum(pT) # Needs time dimension as axis [0] and probability density as axis [1]\n",
    "\n",
    "def normalizeData(data):\n",
    "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    p = p + .5\n",
    "    q = q + .5\n",
    "    return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "def combine_anticipatory_sensory(pTrialOnset, pAntic, k):\n",
    "    pAntic = pAntic * k\n",
    "    t = np.stack((normalize_rt_pdfs(pTrialOnset), pAntic), axis = 1)\n",
    "    return normalize_rt_pdfs(t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Behavioural_Data'\n",
    "subj_path = r'E:\\Free Choice\\Data\\tDCS\\tDCS\\Final Data'\n",
    "subj_keys = behaviour.get_immediate_subdirectories(subj_path)\n",
    "polarity_keys = ['AN', 'CA']\n",
    "exp_keys = ['PR','ST', 'PO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probabilities contain nan\n"
     ]
    }
   ],
   "source": [
    "## Fit Model to all Data\n",
    "from scipy.optimize import differential_evolution\n",
    "from skopt import dump\n",
    "\n",
    "for subj in subj_keys:\n",
    "    for polarity in polarity_keys:\n",
    "        for exp in exp_keys:\n",
    "            data = behaviour.combineBehaviour(path = path, all_key = False, subj_key= subj,\n",
    "                                              polarity_key = polarity, exp_key = exp)\n",
    "            bnds = ((1e-8, 1), (1e-5, 2), (1e-6, 1e-1), (0.0001, 1))\n",
    "            modelFit = differential_evolution(fiteLATERModel, bounds = bnds, args=([data]))\n",
    "            dump(modelFit, fr'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Model_Fits\\eLATERfit_{subj}_{polarity}_{exp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBDIFit(modelFit, data, numBins, minDelay, maxDelay):\n",
    "    \"\"\" Plotting function for returning pdf and cdf of model vs data. \n",
    "    Arguments follow previous conventions. \n",
    "    \"\"\"\n",
    "\n",
    "    # Compute recovered model\n",
    "    recoveredModel = eLATER('Accumulator 1', time = np.arange(1,2000), muR = modelFit.x[0], muS = modelFit.x[1],\n",
    "                           sigR = modelFit.x[2], sigS = modelFit.x[3], maxT = 700)\n",
    "    \n",
    "    # Return binned delay data for plotting\n",
    "    delayidx = behaviour.binDelaydata(data, minDelay = minDelay, maxDelay = maxDelay, numBins = numBins)            \n",
    "    delays= np.linspace(minDelay, maxDelay, numBins)\n",
    "    \n",
    "    # Set plotting colours\n",
    "    _ , axs = plt.subplots(2, 2, figsize=(12,4))\n",
    "    color = iter(cm.BuPu(np.linspace(0.1, 1, 10)))\n",
    "\n",
    "    # Loop over delay bins and plot data overlayed with model\n",
    "    for delay in delays[:-1]:\n",
    "        data = delayidx[str(delay)]['Reaction Time: First Target'] + delay #Align to delay time \n",
    "        data = data.to_numpy()\n",
    "\n",
    "        # Run model on single delay \n",
    "        recoveredModel.setDelayTimes(np.linspace(delay, delay, 1))\n",
    "        recoveredModel.computeModel()\n",
    "\n",
    "        # Plot results\n",
    "        c = next(color)\n",
    "        axs[0,0].plot(recoveredModel.combined, c = c)\n",
    "        axs[0,0].hist(data, bins = 500, density = True, color = c)\n",
    "        axs[0,0].set_title('PDF Model vs Data')\n",
    "        axs[0,0].set_xlim([750, 2000])\n",
    "\n",
    "        axs[1,0].plot(np.cumsum(recoveredModel.combined), c =  c)\n",
    "        axs[1,0].set_title('CDF Model')\n",
    "        axs[1,0].set_xlim([750, 2000])\n",
    "    plt.savefig(rf\"C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Figures\\example model\", format='svg')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelFit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Notebooks\\14_Compare_ELATER_BDI.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plotBDIFit(modelFit, data, numBins \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, minDelay \u001b[39m=\u001b[39m \u001b[39m750\u001b[39m, maxDelay \u001b[39m=\u001b[39m \u001b[39m1250\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(modelFit\u001b[39m.\u001b[39mfun)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'modelFit' is not defined"
     ]
    }
   ],
   "source": [
    "plotBDIFit(modelFit, data, numBins = 10, minDelay = 750, maxDelay = 1250)\n",
    "\n",
    "print(modelFit.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.optimize._optimize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Notebooks\\14_Compare_ELATER_BDI.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m exp \u001b[39min\u001b[39;00m exp_keys:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     eLATER_Model \u001b[39m=\u001b[39m load(\u001b[39mfr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBrandon\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPhD\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBaseline Dynamics\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBaseline-Dynamics\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mModel_Fits\u001b[39m\u001b[39m\\\u001b[39m\u001b[39meLATERfit_\u001b[39m\u001b[39m{\u001b[39;00msubj\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mpolarity\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mexp\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     baseline_Model \u001b[39m=\u001b[39m load(\u001b[39mfr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mBrandon\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPhD\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mBaseline Dynamics\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mBaseline-Dynamics\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mModel_Fits\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mmodelfit_\u001b[39;49m\u001b[39m{\u001b[39;49;00msubj\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mpolarity\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mexp\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     plt\u001b[39m.\u001b[39mbar(counter, eLATER_Model\u001b[39m.\u001b[39mfun \u001b[39m-\u001b[39m baseline_Model\u001b[39m.\u001b[39mfun, color \u001b[39m=\u001b[39m c)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     counter \u001b[39m=\u001b[39m counter \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\venv\\lib\\site-packages\\skopt\\utils.py:174\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    152\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39m    Reconstruct a skopt optimization result from a file\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m    persisted with skopt.dump.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39m        Reconstructed OptimizeResult instance.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m load_(filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(name) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(module) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[39mraise\u001b[39;00m UnpicklingError(\u001b[39m\"\u001b[39m\u001b[39mSTACK_GLOBAL requires str\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_class(module, name))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[39melif\u001b[39;00m module \u001b[39min\u001b[39;00m _compat_pickle\u001b[39m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1579\u001b[0m         module \u001b[39m=\u001b[39m _compat_pickle\u001b[39m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1580\u001b[0m \u001b[39m__import__\u001b[39;49m(module, level\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _getattribute(sys\u001b[39m.\u001b[39mmodules[module], name)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy.optimize._optimize'"
     ]
    }
   ],
   "source": [
    "from skopt import load\n",
    "import matplotlib.pyplot as plt\n",
    "counter = 1\n",
    "color = iter(cm.twilight(np.linspace(0.1, 1, 7)))\n",
    "for subj in subj_keys:\n",
    "    c = next(color)\n",
    "    for polarity in polarity_keys:\n",
    "        for exp in exp_keys:\n",
    "            eLATER_Model = load(fr'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Model_Fits\\eLATERfit_{subj}_{polarity}_{exp}')\n",
    "            baseline_Model = load(fr'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Model_Fits\\modelfit_{subj}_{polarity}_{exp}')\n",
    "            plt.bar(counter, eLATER_Model.fun - baseline_Model.fun, color = c)\n",
    "            counter = counter + 1\n",
    "\n",
    "\n",
    "#plt.savefig(rf\"C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Figures\\eLATER vs Baseline Model\", format='svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.optimize._optimize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Notebooks\\14_Compare_ELATER_BDI.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mskopt\u001b[39;00m \u001b[39mimport\u001b[39;00m load\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m eLATER_Model \u001b[39m=\u001b[39m load(\u001b[39mfr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mUsers\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBrandon\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDesktop\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPhD\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBaseline Dynamics\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mBaseline-Dynamics\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mModel_Fits\u001b[39m\u001b[39m\\\u001b[39m\u001b[39meLATERfit_\u001b[39m\u001b[39m{\u001b[39;00msubj\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mpolarity\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mexp\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Brandon/Desktop/PhD/Baseline%20Dynamics/Baseline-Dynamics/Notebooks/14_Compare_ELATER_BDI.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m baseline_Model \u001b[39m=\u001b[39m load(\u001b[39mfr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mBrandon\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mPhD\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mBaseline Dynamics\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mBaseline-Dynamics\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mModel_Fits\u001b[39;49m\u001b[39m\\\u001b[39;49m\u001b[39mmodelfit_\u001b[39;49m\u001b[39m{\u001b[39;49;00msubj\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mpolarity\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mexp\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\venv\\lib\\site-packages\\skopt\\utils.py:174\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    152\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[39m    Reconstruct a skopt optimization result from a file\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m    persisted with skopt.dump.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[39m        Reconstructed OptimizeResult instance.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mreturn\u001b[39;00m load_(filename, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\venv\\lib\\site-packages\\joblib\\numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\pickle.py:1538\u001b[0m, in \u001b[0;36m_Unpickler.load_stack_global\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(name) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mtype\u001b[39m(module) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m:\n\u001b[0;32m   1537\u001b[0m     \u001b[39mraise\u001b[39;00m UnpicklingError(\u001b[39m\"\u001b[39m\u001b[39mSTACK_GLOBAL requires str\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_class(module, name))\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\pickle.py:1580\u001b[0m, in \u001b[0;36m_Unpickler.find_class\u001b[1;34m(self, module, name)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     \u001b[39melif\u001b[39;00m module \u001b[39min\u001b[39;00m _compat_pickle\u001b[39m.\u001b[39mIMPORT_MAPPING:\n\u001b[0;32m   1579\u001b[0m         module \u001b[39m=\u001b[39m _compat_pickle\u001b[39m.\u001b[39mIMPORT_MAPPING[module]\n\u001b[1;32m-> 1580\u001b[0m \u001b[39m__import__\u001b[39;49m(module, level\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _getattribute(sys\u001b[39m.\u001b[39mmodules[module], name)[\u001b[39m0\u001b[39m]\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scipy.optimize._optimize'"
     ]
    }
   ],
   "source": [
    "from skopt import load\n",
    "eLATER_Model = load(fr'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Model_Fits\\eLATERfit_{subj}_{polarity}_{exp}')\n",
    "baseline_Model = load(fr'C:\\Users\\Brandon\\Desktop\\PhD\\Baseline Dynamics\\Baseline-Dynamics\\Model_Fits\\modelfit_{subj}_{polarity}_{exp}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
